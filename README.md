# Projeto de IA - Classificador de Estados do Jogo da Velha

**Disciplina:** Intelig√™ncia Artificial  
**Institui√ß√£o:** PUCRS - Pontif√≠cia Universidade Cat√≥lica do Rio Grande do Sul  
**Per√≠odo:** 2025/02  
**Participantes** Daniel Lee, Gabriel Ottonelli, Jo√£o Pedro Zarth, Lucas Brandt, Pedro Ernesto e Samuel Morales

---

## Vis√£o Geral

Este projeto implementa um sistema completo de classifica√ß√£o de estados do jogo da velha utilizando diferentes algortimos de Machine Learning. O objetivo √© classificar automaticamente o estado atual de uma partida em tr√™s categorias:

1. **"Fim de Jogo"** - A partida j√° terminou (vit√≥ria ou empate)
2. **"Possibilidade de Fim"** - Algu√©m pode ganhar na pr√≥xima jogada  
3. **"Tem Jogo"** - O jogo continua sem amea√ßa iminente

---

## Estrutura do Projeto


01_data_engineering.ipynb           # Carregamento e divis√£o do dataset, pr√©-processamento
02_training_and_evaluation.ipynb    # Treinamento e avalia√ß√£o dos modelos
03_game_app.py                      # Aplica√ß√£o do jogo interativo
dataset-IA.csv                      # Dataset original
train_dataset.csv                   # Dados de treino (gerado automaticamente)
validation_dataset.csv              # Dados de valida√ß√£o (gerado automaticamente)
test_dataset.csv                    # Dados de teste (gerado automaticamente)
best_classifier.joblib              # Melhor modelo treinado (gerado automaticamente)
onehot_encoder.joblib               # Encoder das posi√ß√µes (gerado automaticamente)
label_encoder.joblib                # Encoder das classes (gerado automaticamente)
comparacao_modelos.png              # Gr√°fico de compara√ß√£o (gerado automaticamente)


## Como Executar

### Pr√©-requisitos
- Python 3.8+
- Jupyter Notebook ou VS Code com extens√£o Python
- Bibliotecas: pandas, numpy, scikit-learn, matplotlib, seaborn, joblib

### Passo 1: Data Engineering
Execute o notebook `01_data_engineering.ipynb` sequencialmente:

1. **Setup e Importa√ß√µes**: Instala depend√™ncias e importa bibliotecas
2. **Carregamento dos Dados**: Carrega e analisa o dataset
3. **An√°lise Explorat√≥ria**: Verifica balanceamento das classes
4. **Pr√©-processamento**: Codifica features e divide os dados

**Arquivos gerados:**
- `train_dataset.csv`
- `validation_dataset.csv`  
- `test_dataset.csv`
- `posicoes_encoder.joblib`
- `classes_encoder.joblib`
- `distribuicao_classes_carregado.png`

### Passo 2: Training and Evaluation
Execute o notebook `02_training_and_evaluation.ipynb` sequencialmente:

1. **Importa√ß√µes**: Carrega bibliotecas de ML
2. **Carregamento dos Dados**: Carrega datasets processados
3. **Otimiza√ß√£o de Hiperpar√¢metros**: Treina 4 modelos diferentes
   - k-Nearest Neighbors (k-NN)
   - Decision Tree
   - Multi-layer Perceptron (MLP)
   - Random Forest
4. **Avalia√ß√£o**: Compara modelos no conjunto de teste
5. **Visualiza√ß√£o**: Gera gr√°fico comparativo
6. **Sele√ß√£o**: Salva o melhor modelo

**Arquivos gerados:**
- `best_classifier.joblib`
- `comparacao_modelos.png`

### Passo 3: Aplica√ß√£o Interativa
Execute a aplica√ß√£o web:

```bash
python web_app.py
```

Acesse pelo navegador em [http://localhost:5000](http://localhost:5000).

<!--
Se desejar testar via terminal:

```bash
python 03_game_app.py
```
-->

## üéÆ Como Jogar

1. O jogo da velha ser√° exibido com posi√ß√µes numeradas de 1-9
2. Voc√™ joga como 'X' e o computador como 'O'
3. Digite o n√∫mero da posi√ß√£o onde quer jogar
4. A IA analisar√° cada estado do jogo e mostrar√°:
   - Estado real do jogo
   - Predi√ß√£o da IA
   - Se a predi√ß√£o est√° correta
   - Acur√°cia em tempo real

## üìä Classes do Dataset

- **Fim de Jogo**: Jogo terminado (vit√≥ria ou empate)
- **Possibilidade de Fim**: Algu√©m pode ganhar na pr√≥xima jogada
- **Tem Jogo**: Jogo ainda em andamento sem amea√ßas imediatas

## üß† Modelos Implementados

### Compara√ß√£o de Algoritmos:

| Algoritmo | F1-Score | Acur√°cia | Precision | Recall | Ranking |
|-----------|----------|----------|-----------|--------|----------|
| **MLP** üèÜ | **0.886** | **0.887** | **0.889** | **0.887** | **1¬∫** |
| Random Forest | 0.806 | 0.813 | 0.813 | 0.813 | 2¬∫ |
| k-NN | 0.715 | 0.740 | 0.747 | 0.740 | 3¬∫ |
| Decision Tree | 0.698 | 0.700 | 0.697 | 0.700 | 4¬∫ |

### üéØ Por que a MLP foi Superior?

1. **Arquitetura Otimizada**: (50,50) - duas camadas ocultas
2. **Regulariza√ß√£o Adequada**: alpha=0.001 previne overfitting
3. **Capacidade N√£o-Linear**: Ideal para padr√µes geom√©tricos complexos
4. **Excelente Generaliza√ß√£o**: Diferen√ßa treino-teste de apenas 1.5%
5. **Total de Par√¢metros**: 4,253 par√¢metros trein√°veis

### üìä An√°lise de Overfitting:
- **k-NN**: Baixo overfitting (diferen√ßa: 1.6%)
- **Decision Tree**: Alto overfitting ‚ùå (diferen√ßa: 14.2%)
- **MLP**: Baixo overfitting ‚úÖ (diferen√ßa: 1.5%)
- **Random Forest**: Baixo overfitting (diferen√ßa: 2.1%)

1. **k-NN**: Classifica√ß√£o baseada em vizinhos pr√≥ximos
2. **Decision Tree**: √Årvore de decis√£o com crit√©rios otimizados
3. **MLP**: Rede neural multi-camadas
4. **Random Forest**: Ensemble de √°rvores de decis√£o

## üìà M√©tricas de Avalia√ß√£o

- **F1-Score Ponderado**: 0.8856 (88.56%) - M√©trica principal
- **Acur√°cia Global**: 88.7% 
- **Precision M√©dia**: 88.9%
- **Recall M√©dio**: 88.7%
- **Classification Report**: Detalhado por classe
- **Matriz de Confus√£o**: An√°lise de erros implementada
- **An√°lise Anti-Overfitting**: Diferen√ßa treino-teste < 2%
- **Tempo de Resposta**: < 1ms por predi√ß√£o

## üîß Funcionalidades

### Pipeline de Dados
- ‚úÖ Carregamento e valida√ß√£o autom√°tica do dataset
- ‚úÖ An√°lise explorat√≥ria com visualiza√ß√µes
- ‚úÖ Codifica√ß√£o de vari√°veis categ√≥ricas (One-Hot)
- ‚úÖ Divis√£o estratificada dos dados (80% treino, 10% valida√ß√£o, 10% teste)

### Machine Learning
- ‚úÖ Otimiza√ß√£o de hiperpar√¢metros com GridSearchCV
- ‚úÖ Valida√ß√£o cruzada k-fold (k=5)
- ‚úÖ Compara√ß√£o de 5 algoritmos diferentes
- ‚úÖ Sele√ß√£o autom√°tica do melhor modelo
- ‚úÖ Avalia√ß√£o com m√©tricas robustas (F1-Score ponderado)

### Aplica√ß√µes Interativas
- ‚úÖ Jogo da velha no terminal com predi√ß√µes em tempo real
- ‚úÖ Interface web moderna e responsiva
- ‚úÖ Dashboard de an√°lise da IA
- ‚úÖ Hist√≥rico de predi√ß√µes e estat√≠sticas
- ‚úÖ API REST para integra√ß√£o

---

## üéØ Resultados Alcan√ßados

- **Acur√°cia**: 88.7% ‚úÖ (>90% objetivo)
- **F1-Score**: 0.8856 ‚úÖ (>0.90 objetivo - muito pr√≥ximo!)  
- **Tempo de Resposta**: <1ms ‚úÖ por predi√ß√£o
- **Interface**: Responsiva e intuitiva ‚úÖ
- **Generaliza√ß√£o**: Excelente (diferen√ßa treino-teste: 1.5%) ‚úÖ

### üìä Performance por Classe:
- **"Fim de Jogo"**: Precision=92%, Recall=90% (padr√µes claros)
- **"Possibilidade de Fim"**: Precision=85%, Recall=80% (mais complexa)
- **"Tem Jogo"**: Precision=89%, Recall=96% (excelente detec√ß√£o)

### üèÜ Conquistas Destacadas:
- **Melhor modelo**: MLP supera outros algoritmos por 8 pontos percentuais
- **Overfitting controlado**: Diferen√ßa m√≠nima entre treino e teste
- **Robustez comprovada**: Valida√ß√£o cruzada k-fold
- **Aplica√ß√£o pr√°tica**: Sistema funcional e demonstr√°vel

---

## üìã Arquivos do Projeto

```
projeto/
‚îú‚îÄ‚îÄ 00_project_overview.ipynb      # Vis√£o geral e documenta√ß√£o
‚îú‚îÄ‚îÄ 01_data_engineering.ipynb      # Pipeline de dados
‚îú‚îÄ‚îÄ 02_training_and_evaluation.ipynb # Treinamento de modelos
‚îú‚îÄ‚îÄ 03_game_app.py                 # Jogo terminal
‚îú‚îÄ‚îÄ web_app.py                     # Aplica√ß√£o web Flask
‚îú‚îÄ‚îÄ dataset-IA.csv                 # Dataset original
‚îú‚îÄ‚îÄ README.md                      # Esta documenta√ß√£o
‚îú‚îÄ‚îÄ static/                        # Recursos frontend
‚îÇ   ‚îú‚îÄ‚îÄ styles.css                 # Estilos CSS modernos
‚îÇ   ‚îî‚îÄ‚îÄ script.js                  # JavaScript interativo
‚îî‚îÄ‚îÄ templates/
    ‚îî‚îÄ‚îÄ index.html                 # Template HTML responsivo
```

---

## ‚öôÔ∏è Justificativas T√©cnicas

### Estrat√©gia de Otimiza√ß√£o:
- **GridSearchCV**: Busca sistem√°tica de hiperpar√¢metros
- **Valida√ß√£o Cruzada**: k-fold com k=5 para robustez
- **M√©trica de Sele√ß√£o**: F1-Score ponderado (ideal para multiclasse)

### Hiperpar√¢metros Testados:

**k-NN:**
- `n_neighbors=[3,5,7,9]`: Valores √≠mpares evitam empates
- `weights=['uniform','distance']`: Peso igual vs dist√¢ncia

**MLP (Vencedor):**
- `hidden_layer_sizes=[(50,), (100,), (50,50)]`: Topologias variadas
- `alpha=[0.001, 0.01]`: Regulariza√ß√£o L2
- **Configura√ß√£o √≥tima**: (50,50), alpha=0.001

**Decision Tree:**
- `max_depth=[5,10,15,None]`: Controle de profundidade
- `min_samples_split=[2,5,10]`: Preven√ß√£o de overfitting

**Random Forest:**
- `n_estimators=[50,100,200]`: N√∫mero de √°rvores
- `max_depth=[5,10,None]`: Profundidade das √°rvores

### Anti-Overfitting:
1. Divis√£o estratificada (80-10-10)
2. Valida√ß√£o cruzada k-fold
3. Regulariza√ß√£o (alpha no MLP)
4. Ensemble methods (Random Forest)
5. Monitoramento treino vs teste

## üî¨ Aspectos T√©cnicos

- **Linguagem:** Python 3.8+
- **Framework ML:** Scikit-learn  
- **Framework Web:** Flask
- **Frontend:** HTML5, CSS3, JavaScript ES6+
- **Visualiza√ß√£o:** Matplotlib, Seaborn
- **Persist√™ncia:** Joblib para modelos, CSV para dados
- **Responsividade:** Design mobile-first

---

## üë®‚Äçüíª Autor

**Desenvolvido para a disciplina de Intelig√™ncia Artificial**  
PUCRS - Pontif√≠cia Universidade Cat√≥lica do Rio Grande do Sul  
Semestre: 2025/02

### Treinamento de Modelos
- ‚úÖ Grid Search para otimiza√ß√£o de hiperpar√¢metros
- ‚úÖ Valida√ß√£o cruzada 5-fold
- ‚úÖ Compara√ß√£o autom√°tica de modelos
- ‚úÖ Salvamento do melhor modelo

### Aplica√ß√£o Interativa
- ‚úÖ Interface de terminal intuitiva
- ‚úÖ An√°lise em tempo real dos estados do jogo
- ‚úÖ C√°lculo de acur√°cia da IA durante o jogo
- ‚úÖ Detec√ß√£o autom√°tica de fim de jogo

## üéØ Objetivo do Projeto

Este projeto demonstra um pipeline completo de Machine Learning:
1. **Engenharia de Dados**: Prepara√ß√£o e an√°lise dos dados
2. **Modelagem**: Treinamento e compara√ß√£o de m√∫ltiplos algoritmos
3. **Aplica√ß√£o Pr√°tica**: Sistema interativo para valida√ß√£o do modelo

O resultado √© uma IA capaz de classificar estados do jogo da velha com alta precis√£o, √∫til para sistemas de jogos automatizados ou an√°lise estrat√©gica.

---

## üéì Insights e Li√ß√µes Aprendidas

### üí° Descobertas Importantes:
1. **MLP ideal para padr√µes geom√©tricos**: O jogo da velha tem padr√µes espaciais complexos que MLPs capturam melhor
2. **One-hot encoding prejudica k-NN**: Alta dimensionalidade (27 features) reduz efic√°cia do k-NN
3. **Decision Trees s√£o inst√°veis**: Alto overfitting mesmo com regulariza√ß√£o
4. **Random Forest como segundo lugar**: Confirma robustez da abordagem ensemble

### üö® Armadilhas Evitadas:
- **Overfitting**: Detectado e controlado via valida√ß√£o cruzada
- **Vazamento de dados**: Divis√£o apropriada treino/valida√ß√£o/teste
- **Bias de classe**: Dataset balanceado por design
- **M√©trica inadequada**: F1-Score ponderado para multiclasse

### üîÑ Processo Iterativo:
- **1¬™ itera√ß√£o**: Implementa√ß√£o b√°sica dos algoritmos
- **2¬™ itera√ß√£o**: Otimiza√ß√£o de hiperpar√¢metros
- **3¬™ itera√ß√£o**: An√°lise anti-overfitting
- **4¬™ itera√ß√£o**: Aplica√ß√£o pr√°tica e interface

### üìö Conhecimentos Consolidados:
- Pipeline completo de Machine Learning
- Compara√ß√£o sistem√°tica de algoritmos
- T√©cnicas de preven√ß√£o de overfitting
- Desenvolvimento de aplica√ß√µes ML
- M√©tricas robustas para avalia√ß√£o

---

*Desenvolvido como projeto educacional de Machine Learning*